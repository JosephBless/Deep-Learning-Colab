{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Write_An_Assembler",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Write A Genome Assembler with ``blasr`` and ``(I)Python``\n",
        "=========================================================="
      ],
      "metadata": {
        "id": "RpBqaelkvuv-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction\n",
        "============\n",
        "\n",
        "I am not sure it is right thing to do some coding in a vacation. (See\n",
        "[this tweet](https://twitter.com/pm/status/284102222416056320), not sure if I would agree.)\n",
        "Anyway, before the vacation, I decided to organize whole bunch of random papers\n",
        "I collected in the last few years in my laptop. I eventually felt that I should\n",
        "read some of some theoretical papers about genome assembly again. I grabbed\n",
        "[Gene Meyer's paper](http://bioinformatics.oxfordjournals.org/content/21/suppl_2/ii79.abstract),\n",
        "and started to think about the problem about constructing unitigs\n",
        "(high-confident contigs). Before I tried to read the paper in detail, I just\n",
        "felt maybe that it was useful to write some quick code to check out what real\n",
        "data looked like. I started writing some code visualizing the local overlapping\n",
        "and generating the global overlapping graph. It was pretty straight forward and quite\n",
        "inspiring from the visualization. The visualization motived me to write\n",
        "more ad-hoc code in IPython to go beyond generating simple visualization during the\n",
        "vacation. I started to implement a very simple greedy algorithm to connect the\n",
        "input DNA fragments.  Eventually, I found I can atucally get the whole genome\n",
        "assembly right!! This Notebook shows the work step by step toward a simple genome\n",
        "assembler for long read data using ``IPython`` and ``Python``.\n",
        "\n",
        "The input data was the E. coli K12 data from PacBio(R)\n",
        "[DevNet Site](https://github.com/PacificBiosciences/DevNet/wiki/Hierarchical-Genome-Assembly-Process-%28HGAP%29).\n",
        "I generated a new set of pre-assembled reads as the input DNA fragment using\n",
        "[HBAR-DTK](https://github.com/PacificBiosciences/HBAR-DTK). The statistics of\n",
        "the input reads is shown below:\n",
        "\n",
        "    Pre-assembled Read Stats\n",
        "    #Seqs   17497\n",
        "    Min     448\n",
        "    1st Qu. 5365\n",
        "    Median  6149\n",
        "    Mean    6193\n",
        "    3rd Qu. 7189\n",
        "    Max     14762\n",
        "    Total   108363627\n",
        "    n50     6521\n",
        "    n90     4694\n",
        "    n95     3864\n",
        "\n",
        "This is about 23x of average length of 6.2kb reads of E. coli K12 genome. The\n",
        "mean sequence identity when aligning the pre-assembled reads to the canonical\n",
        "E. coli K12 reference is 99.787% (median identity = 99.921%). The pre-assembled\n",
        "read data is available for download from\n",
        "[this link to pre_assembled_read.fa](http://files.figshare.com/1004577/pre_assembled_reads.fa). According the\n",
        "Lander-Waterman statistics, this set of reads is enough to get single contig\n",
        "for the single chromosome. The only thing one needs to worry about is that\n",
        "whether the repeats in genome can be uniquely. Since it is shown one can use\n",
        "Celera Assembler to assemble this data set into one single contig, this implies\n",
        "that all of the repeats of the rRNA operon can be resolved from this data set.\n",
        "Typically, one might need multiple libraries, especially those long jumping\n",
        "libraries, to resolve long repeats from short read (~100bp) data. For example,\n",
        "ALLPATHS-LG can use multiple short-read libraries and long read data to get\n",
        "perfect assemblies for bacteria\n",
        "[Paper](http://genome.cshlp.org/content/early/2012/07/24/gr.141515.112.abstract)\n",
        "[ALLPATHS-LG Blog](http://www.broadinstitute.org/software/allpaths-lg/blog/?page_id=14). However,\n",
        "when one can get long range information from one single library, the assembly\n",
        "process can be probably greatly simplified.  As demonstrated here, one can\n",
        "actually get pretty good assembly using Python code with blasr for overlapping and\n",
        "Quiver for polishing the residual errors.\n",
        "\n",
        "For long read data, the de Bruijn graph with some sophisticated graph\n",
        "operations to get around the limit of short read data to assemble genomes may\n",
        "not be the right approach. The Overlap-Layout-Consensus can be much more\n",
        "efficient for assembling long reads. Also, when the reads are getting longer,\n",
        "the overlapping between the reads becomes more and more specific. This will\n",
        "significantly reduce the complexity of the overlapping graph between the reads.\n",
        "(Here we define an overlapping graph as a graph where the nodes are reads and\n",
        "the edges are constructed from the pairs of proper overlapped reads.) When the\n",
        "overlapping graph is simple, it becomes possible to use some naive algorithm to\n",
        "get a reasonably good assembly. To make this clear, one can image if the read\n",
        "lengths are as long as the genome, the number of overlapping one needs to worry\n",
        "about will be in single digit and there will be no ambiguity at all. The\n",
        "overlapping and layout will be trivial in such extreme case.\n",
        "\n",
        "When I use [Celera Assembler (CA)](http://sourceforge.net/projects/wgs-assembler/)\n",
        "to assemble genomes, I always try to peek the\n",
        "intermediate data in order to understand the process better and maybe fix few\n",
        "things manually. [Michael Schatz](http://schatzlab.cshl.edu/) ([@mike_schatz](https://twitter.com/mike_schatz))\n",
        "and [Adam Phillippy](https://twitter.com/aphillippy) both pointed to me\n",
        "some very useful information about CA.  (Thanks, Michael and Adam.)\n",
        "``tigStore`` is a very useful command to see the relationship between the\n",
        "generated unitigs and the initial DNA fragments.  The file\n",
        "``4-unitigger/best.edges`` contains the information best overlapped reads which\n",
        "one can use to construct the overlapping graph and one can learn a lot subtle\n",
        "points about genome assembly by visualizing those.  This notebook is definitely\n",
        "inspired by the great work done by the CA's developers.\n",
        "\n",
        "This IPython notebook is just a \"Notebook\". I write these code for fun and for\n",
        "(self-)educational purposes. It shows that given the good long read data and\n",
        "the proper tools [``blasr``](https://github.com/PacificBiosciences/blasr),\n",
        "[``pbdagcon``](https://github.com/PacificBiosciences/pbdagcon),\n",
        "[``HBAR-DTK``](https://github.com/PacificBiosciences/HBAR-DTK), and\n",
        "[``quiver``](https://github.com/PacificBiosciences/GenomicConsensus) one can learn how to\n",
        "do genome assembly with a \"not-so-high-performance\" language [``Python``](http://python.org).  The great\n",
        "[``IPython Notebook``](http://ipython.org/) allows me to try out different\n",
        "code snippet and different algorithm ideas without a lot of overhead. One\n",
        "should notice this code in this ``IPython Notebook`` is mainly for fun, not for\n",
        "\"production\". I chose the least resistant path for coding.  Coding style and\n",
        "code performance were considered but not taking seriously as I was doing a lot\n",
        "of experiments for different algorithm approaches when I coded this notebook.\n",
        "\n",
        "I consider this Notebook is as a personal project for fun. The data and the\n",
        "used software can be all downloaded publicly.  Although I am an employee of\n",
        "PacBio(R), this notebook is developed in my own time. PacBio will not be\n",
        "responsible for any information associated with this Notebook.  \n",
        "\n",
        "--[Jason Chin](https://twitter.com/infoecho), Apr 2, 2013\n",
        "\n"
      ],
      "metadata": {
        "id": "-qAzcu5XvuwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get Data\n",
        "--------\n",
        "I put the pre-assembled read file in [Figshare](http://figshare.com). Here is [the link to the pre_assembled_read.fa](http://files.figshare.com/1004577/pre_assembled_reads.fa).\n",
        "For most of part of the Notebook, one does not need the fasta file. You can also visit [the project data page](http://figshare.com/articles/Write_a_Genome_Assembler_in_Python_IPython/666737) to see other data files and this code."
      ],
      "metadata": {
        "id": "gME1LSc1vuwJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overlapping\n",
        "-----------\n",
        "The first step to assemble the genome is to use ``blasr`` to find the overlapping between the reads. This can be done by executing this commend:\n",
        "\n",
        "    blasr pre_assembled_reads.fa pre_assembled_reads.fa -m 4 -nproc 32 -bestn 32 -maxLCPLength 15 -nCandidates 36 -out pr_pr_bn32.m4 -noSplitSubreads\n",
        "\n",
        "We ask ``blasr`` to output the coordinates of the alignment between the reads by specified the ``-m 4`` option.\n",
        "The ``-nproc 32`` will let ``blasr`` to use 32 threads.  For each reads, we allow ``blasr`` to find the other 32 best overlaps by using ``-bestn 32`` and scaning 36 potential hit candidateswith ``-nCandidates 36``. The ``-noSplitSubreads`` has only cosmatic effect here. It makes the ouput query identifier cleaner.\n",
        "\n",
        "``blasr`` is a general purpose aligner. It is not really tuned to do overlapping work. One will see sometimes it does not handle the ends of the alignment as one would like it to do. The ``containment_tolerance`` variables used below was introduced for being less picky at the ends of the alignment. However, one would need to worry about potential mis-assemblies if the tolerance is too big.\n",
        "\n",
        "The aligned results can be found in the FigShare project page mentioned above. Or, one can download it from [this link]( http://files.figshare.com/1004576/pr_pr_bn32.m4)."
      ],
      "metadata": {
        "id": "b4jRooTkvuwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"``blasr -m 4``\" output format\n",
        "------------------------------\n",
        "The cells below show the content of the ``m4``  file. It containes the alignment information between the reads. The fields are ``query identifier``, ``target identifier``, ``alignment score (more negative -> better alignment)``, ``alignment identity``, ``query strand``, ``query start``, ``query end``, ``query length``, ``target strand``, ``target start``, ``target end``, ``target length``.   The rest of the fields are not used.  One trap here is that the \"``target start``\" and \"``target end``\" are not relative to the original sequence if \"``target strand``\"  is ``1`` .  When \"``target strand= 1``\", it means that the reverse-complimentary strand is aligned and the \"``target start``\" and \"``target end``\" are the coordinates in the reverse complimentary strand.  In the stand ``blasr`` output, \"``query strand``\" is always ``0``.\n"
      ],
      "metadata": {
        "id": "NSjV69RpvuwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!head -10 pr_pr_bn32.m4"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0xc4b462ba_0096978 0xc4b462ba_0096978 -14495 100 0 0 2899 2899 0 0 2899 2899 50 60847 -2716.48 0 21\r\n",
            "0xc4b462ba_0096978 0x79c77458_0006261 -14400 99.4505 0 0 2899 2899 1 2502 5411 10399 50 60890 -2683.04 0 21\r\n",
            "0xc4b462ba_0096978 0x72a8c4f1_0018952 -14395 99.4164 0 0 2899 2899 0 483 3393 5755 50 60893 -2658.33 0 21\r\n",
            "0xc4b462ba_0096978 0x4dd7c9d5_0133333 -14390 99.4162 0 0 2899 2899 1 2718 5626 6023 50 60894 -2683.04 0 21\r\n",
            "0xc4b462ba_0096978 0x726e8550_0094067 -14385 99.3821 0 0 2899 2899 0 27 2936 7163 50 60897 -2658.76 0 21\r\n",
            "0xc4b462ba_0096978 0x833174a6_0078354 -14385 99.3821 0 0 2899 2899 1 2676 5585 6916 50 60897 -2683.28 0 21\r\n",
            "0xc4b462ba_0096978 0xc52dd432_0103092 -14380 99.3819 0 0 2899 2899 1 2565 5472 6025 50 60900 -2666.7 0 21\r\n",
            "0xc4b462ba_0096978 0x48e2fc97_0054635 -14375 99.3477 0 0 2899 2899 0 2621 5529 7539 50 60902 -2658.24 0 21\r\n",
            "0xc4b462ba_0096978 0xea0a0bab_0128842 -14375 99.3477 0 0 2899 2899 0 7684 10592 11923 50 60901 -2657.5 0 21\r\n",
            "0xc4b462ba_0096978 0x4949e7c9_0060870 -14360 99.3132 0 0 2899 2899 1 2927 5832 6621 50 60907 -2666.12 0 21\r\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "A6wHICXgvuwL",
        "outputId": "3d418d63-2c1e-4242-b105-80f9c242da74"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert ``blasr``'s output to python internal data\n",
        "--------------------------------------------------\n",
        "\n",
        "We deinfe ``read_node`` class for the objects that holds the local overlapping information of each read. It simply holds a ``python`` dictionary (hash_map) where the key is the ``target identifier`` and the elements from ``m4`` line are converted to the right types and stored. Only \"non-contaminated\"\" alignments are stored. If one read is full aligned within the other read, such alignment is not stored in a ``read_node``. The ``get_overlap_data`` function processes the ``m4`` file and determine whether the alignments are ``contaminated`` with some tolerence of the ends of the alignments."
      ],
      "metadata": {
        "id": "jXa841vvvuwO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "class read_node_0:  #experimenting on keeping the data in a list rather than a dictionary, not used\n",
        "\n",
        "    def __init__(self, name, length):\n",
        "        self.name = name\n",
        "        self.length = length\n",
        "        self.hits = []\n",
        "        self.hit_map = None\n",
        "\n",
        "    def add_hit(self, aln_info):\n",
        "        self.hits.append ( aln_info )\n",
        "\n",
        "    def __getitem__(self, target_name):\n",
        "        if self.hit_map == None:\n",
        "            self.hit_map = dict(zip( [h[0] for h in self.hits], self.hits ) )\n",
        "        return self.hit_map[target_name]\n",
        "\n",
        "class read_node:\n",
        "\n",
        "    def __init__(self, name, length):\n",
        "        self.name = name\n",
        "        self.length = length\n",
        "        self.hit_map = {}\n",
        "\n",
        "    def add_hit(self, aln_info):\n",
        "        self.hit_map[aln_info[0]] = aln_info\n",
        "\n",
        "    def __getitem__(self, target_name):\n",
        "        return self.hit_map[target_name]\n",
        "\n",
        "    @property\n",
        "    def hits(self):  #another convenient representation of the same data\n",
        "        return self.hit_map.values()\n",
        "\n",
        "\n",
        "def get_overlap_data(m4_filename):\n",
        "    containment_tolerance = 50\n",
        "    permitted_error_pct = 2\n",
        "    overlap_data = {}\n",
        "    contained_reads = set()\n",
        "    with open(m4_filename) as m4_f:\n",
        "        for l in m4_f:\n",
        "            l = l.strip().split()\n",
        "            q_name, t_name =l[0:2]\n",
        "            if q_name == t_name:\n",
        "                continue\n",
        "            aln_score = int(l[2])\n",
        "            aln_idt = float(l[3])\n",
        "\n",
        "            if aln_idt < 100-permitted_error_pct:\n",
        "                continue\n",
        "\n",
        "            q_strand, q_start, q_end, q_len = ( int(x) for x in l[4:8])\n",
        "            t_strand, t_start, t_end, t_len = ( int(x) for x in l[8:12])\n",
        "\n",
        "            if q_len - (q_end - q_start) < containment_tolerance:\n",
        "                contained_reads.add(q_name)\n",
        "\n",
        "            if t_len - (t_end - t_start) < containment_tolerance:\n",
        "                contained_reads.add(t_name)\n",
        "\n",
        "            if q_name not in overlap_data:\n",
        "                overlap_data[ q_name ] = read_node(q_name, q_len)\n",
        "\n",
        "            assert q_strand == 0\n",
        "            if t_name not in [x[0] for x in overlap_data[ q_name ].hits]:\n",
        "                overlap_data[ q_name ].add_hit( (t_name,\n",
        "                                                 aln_score,\n",
        "                                                 aln_idt,\n",
        "                                                 (q_strand, q_start, q_end, q_len),\n",
        "                                                 (t_strand, t_start, t_end, t_len) ) )\n",
        "\n",
        "            #symmetrized the alignment record\n",
        "            if t_name not in overlap_data:\n",
        "                overlap_data[ t_name ] = read_node(t_name, t_len)\n",
        "\n",
        "            if q_name not in [x[0] for x in overlap_data[ t_name ].hits]:\n",
        "                if t_strand == 1:\n",
        "                    t_start, t_end = t_len - t_end, t_len - t_start\n",
        "                    q_start, q_end = q_len - q_end, q_len - q_start\n",
        "                    overlap_data[ t_name ].add_hit( (q_name,\n",
        "                                                 aln_score,\n",
        "                                                 aln_idt,\n",
        "                                                 (0, t_start, t_end, t_len),\n",
        "                                                 (1, q_start, q_end, q_len) ) )\n",
        "                else:\n",
        "                    overlap_data[ t_name ].add_hit( (q_name,\n",
        "                                                 aln_score,\n",
        "                                                 aln_idt,\n",
        "                                                 (0, t_start, t_end, t_len),\n",
        "                                                 (0, q_start, q_end, q_len) ) )\n",
        "    return overlap_data, contained_reads"
      ],
      "outputs": [],
      "metadata": {
        "id": "-TvDONdMvuwO"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "overlap_data, contained_reads = get_overlap_data(\"pr_pr_bn32.m4\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "W-MpWM6GvuwP"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple function to convert the overlapping data to a GML file\n",
        "---------------------------------------------------------------\n",
        "\n",
        "The ``generate_overlap_gml`` takes the ``overlap_data`` and the ``contained_reads`` to generate a overlap graph in ``GML`` format. (You will need to install ``networkx`` in your ``Python`` environment to use this code.)  \n"
      ],
      "metadata": {
        "id": "xB4g8w0xvuwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_overlap_gml(overlap_data, contained_reads, gml_filename):\n",
        "    containment_tolerance = 50\n",
        "    permitted_error_pct = 2\n",
        "    import networkx as nx\n",
        "    G=nx.DiGraph()\n",
        "    node_in_graph = set()\n",
        "    for q_name in overlap_data:\n",
        "        if q_name in contained_reads:\n",
        "            continue\n",
        "        if q_name not in node_in_graph:\n",
        "            G.add_node(q_name)\n",
        "        targets = overlap_data[ q_name ].hits\n",
        "        targets_3prime = [ h for h in targets if h[4][1] < containment_tolerance and h[0] not in contained_reads]\n",
        "        targets_5prime = [ h for h in targets if h[3][1] < containment_tolerance and h[0] not in contained_reads]\n",
        "        targets_3prime.sort(key = lambda k:k[1])\n",
        "        targets_5prime.sort(key = lambda k:k[1])\n",
        "\n",
        "        if len(targets_3prime) > 0:\n",
        "            t = targets_3prime[0]\n",
        "            t_name = t[0]\n",
        "            if t_name not in node_in_graph:\n",
        "                G.add_node(t_name)\n",
        "            G.add_edge(q_name, t_name)\n",
        "\n",
        "        if len(targets_5prime) > 0:\n",
        "            t = targets_5prime[0]\n",
        "            t_name = t[0]\n",
        "            if t_name not in node_in_graph:\n",
        "                G.add_node(t_name)\n",
        "            G.add_edge(q_name, t_name)\n",
        "    nx.write_gml(G, gml_filename)"
      ],
      "outputs": [],
      "metadata": {
        "id": "WLeTqzOvvuwQ"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "generate_overlap_gml(overlap_data, contained_reads, \"overlap_graph.gml\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "fPI0GrpWvuwR"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overlapping graph visualized by Gephi\n",
        "-------------------------------------\n",
        "\n",
        "Ther generated overlap_graph.gml can be visualized by [Gephi](https://gephi.org/). One can\n",
        "use \"YifanHu's Multilevel\" graph layout algorithm to do the rough\n",
        "layout followed by \"ForceAtlas 2\" algorithm to smooth the graph. The cell below shows the\n",
        "global overlapping structure. One can see that it is topologically a circle plus\n",
        "a number of singletons. Namely, the read data does capture the whole genome in\n",
        "one single circular layout."
      ],
      "metadata": {
        "id": "OsslDwGlvuwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image(filename = \"overlap_graph01.png\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 6
        }
      ],
      "metadata": {
        "id": "5OBAz_kVvuwS",
        "outputId": "7b5b3744-09ea-4235-bf96-09460b323e66"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also see some local \"bubbles\" in the graph."
      ],
      "metadata": {
        "id": "Lun-2HkPvuwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename = \"overlap_graph02.png\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 7
        }
      ],
      "metadata": {
        "id": "O2Fqy4CXvuwT",
        "outputId": "73088275-89e2-4997-ecf1-feacaeb204bc"
      },
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename = \"overlap_graph03.png\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 8
        }
      ],
      "metadata": {
        "id": "gE0Q_THcvuwT",
        "outputId": "a5c37c40-a070-4e2c-b96e-6c85e9001eef"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some utility constants, functions and a class for viewing the local overlaping with ``SVG`` files\n",
        "--------------------------------------------------------------------------------------------------\n",
        "\n",
        "The cell below defines some contants and utility funtions so we can generate ``SVG`` to show the local overlapping alignments.\n"
      ],
      "metadata": {
        "id": "dSgLiOl-vuwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arrow_defs = \"\"\"<defs>\n",
        "    <marker id=\"Triangle_green\" stroke=\"green\" fill=\"green\"\n",
        "      viewBox=\"0 0 10 10\" refX=\"0\" refY=\"5\"\n",
        "      markerUnits=\"strokeWidth\"\n",
        "      markerWidth=\"4\" markerHeight=\"3\"\n",
        "      orient=\"auto\">\n",
        "      <path d=\"M 0 0 L 10 5 L 0 10 z\" />\n",
        "    </marker>\n",
        "    <marker id=\"Triangle_blue\" stroke=\"blue\" fill=\"blue\"\n",
        "      viewBox=\"0 0 10 10\" refX=\"0\" refY=\"5\"\n",
        "      markerUnits=\"strokeWidth\"\n",
        "      markerWidth=\"4\" markerHeight=\"3\"\n",
        "      orient=\"auto\">\n",
        "      <path d=\"M 0 0 L 10 5 L 0 10 z\" />\n",
        "    </marker>\n",
        "    <marker id=\"Triangle_black\" stroke=\"black\" fill=\"black\"\n",
        "      viewBox=\"0 0 10 10\" refX=\"0\" refY=\"5\"\n",
        "      markerUnits=\"strokeWidth\"\n",
        "      markerWidth=\"4\" markerHeight=\"3\"\n",
        "      orient=\"auto\">\n",
        "      <path d=\"M 0 0 L 10 5 L 0 10 z\" />\n",
        "    </marker>\n",
        "    <marker id=\"Triangle_red\" stroke=\"red\" fill=\"red\"\n",
        "      viewBox=\"0 0 10 10\" refX=\"0\" refY=\"5\"\n",
        "      markerUnits=\"strokeWidth\"\n",
        "      markerWidth=\"4\" markerHeight=\"3\"\n",
        "      orient=\"auto\">\n",
        "      <path d=\"M 0 0 L 10 5 L 0 10 z\" />\n",
        "    </marker>\n",
        "  </defs>\"\"\"\n",
        "\n",
        "def svg_arrow( x1, y1, x2, y2, col, w):\n",
        "    return \"\"\"<g stroke = \"%s\" stroke-width = \"%f\" fill = \"none\">\\\n",
        "<path d = \"M %f %f L %f %f\" marker-end=\"url(#Triangle_%s)\"/> </g>\"\"\" % (col, w, x1, y1, x2, y2, col)\n",
        "\n",
        "def svg_line( x1, y1, x2, y2, col, w):\n",
        "    return \"\"\"<g stroke = \"%s\" stroke-width = \"%f\" fill = \"none\">\\\n",
        "<path d = \"M %f %f L %f %f\"/> </g>\"\"\" % (col, w, x1, y1, x2, y2)\n",
        "\n",
        "class Overlap_SVG_view:\n",
        "    def __init__(self):\n",
        "        self.header = \"\"\"<?xml version=\"1.0\" standalone=\"no\"?>\n",
        "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
        "<svg xmlns:svg=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\" width=\"900px\" height=\"300px\">\n",
        "\"\"\"\n",
        "        self.footer = \"\"\"</svg>\"\"\"\n",
        "        self.elements = []\n",
        "        self._svg_data = None\n",
        "\n",
        "    def add_element(self, elm):\n",
        "        self.elements.append(elm)\n",
        "\n",
        "    def _construct_SVG(self):\n",
        "        SVG_str = []\n",
        "        SVG_str.append( self.header )\n",
        "        for elm in self.elements:\n",
        "            SVG_str.append( elm )\n",
        "        SVG_str.append( self.footer )\n",
        "        self._svg_data = \"\\n\".join(SVG_str)\n",
        "        self._svg_data = self._svg_data.decode('utf-8')\n",
        "\n",
        "    def output(self, filename):\n",
        "        if self._svg_data is None:\n",
        "            self._construct_SVG()\n",
        "        with open(filename, \"w\") as out_f:\n",
        "            print >> out_f, self._svg_data\n",
        "\n",
        "    def _repr_svg_(self):\n",
        "        if self._svg_data is None:\n",
        "            self._construct_SVG()\n",
        "        return self._svg_data\n",
        "\n",
        "    @property\n",
        "    def svg(self):\n",
        "        return SVG(self._repr_svg_())\n",
        ""
      ],
      "outputs": [],
      "metadata": {
        "id": "HTssFBGzvuwU"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "``generate_overlap_view``: a function taking the overlapping data to generate a ``SVG`` file\n",
        "---------------------------------------------------------------------------------------------\n",
        "\n",
        "The ``generate_overlap_view`` simple does several coordinate transformations to create a ``SVG`` file so we can see the local overlap around a given DNA fragment. The blank arrow indicates the fragment in interesting. Green and blue arrows indicate the forward and reversed proper overlapped alignments. The red arrows indicate containment alignments or improper alignments (locally inconsistent alignments due to repeats, mis-mapping or sequencing artifacts)."
      ],
      "metadata": {
        "id": "T7YB_uhjvuwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "\n",
        "import os\n",
        "\n",
        "def generate_overlap_view(overlap_data, q_name):\n",
        "    containment_tolerance = 10\n",
        "\n",
        "    hits = overlap_data[q_name].hits\n",
        "    SV = Overlap_SVG_view()\n",
        "    SV.add_element(arrow_defs)\n",
        "    x_offset = 10000\n",
        "    x_scaling = 0.02\n",
        "    x1 = 0\n",
        "    x2 = overlap_data[q_name].length\n",
        "    x1 += x_offset\n",
        "    x2 += x_offset\n",
        "    x1 *= x_scaling\n",
        "    x2 *= x_scaling\n",
        "    y = 200\n",
        "    SV.add_element(svg_arrow(x1, y, x2, y, \"black\", 4))\n",
        "    hits.sort(key = lambda k: (k[3][1],k[3][3],k[3][2]))\n",
        "    for h in hits:\n",
        "        t_name, t_score, t_idt = h[0], h[1], h[2]\n",
        "        if t_name in contained_reads:\n",
        "            continue\n",
        "        q_strand, q_start, q_end, q_len = h[3]\n",
        "        t_strand, t_start, t_end, t_len = h[4]\n",
        "        y -=10\n",
        "        x1 = q_start\n",
        "        x2 = q_end\n",
        "        col = None\n",
        "\n",
        "        if q_start < containment_tolerance and t_len - t_end < containment_tolerance:\n",
        "            x1 = -t_start\n",
        "        elif q_len - q_end < containment_tolerance and t_start < containment_tolerance:\n",
        "            x2 = q_end + (t_len - t_end)\n",
        "        else:\n",
        "            col = \"red\"\n",
        "            if t_strand == 1:\n",
        "                x1, x2 = x2, x1\n",
        "            print h\n",
        "        if t_strand == 0 and col == None:\n",
        "            col = \"green\"\n",
        "        elif col == None:\n",
        "            col = \"blue\"\n",
        "            x1, x2 = x2, x1\n",
        "        #print h\n",
        "        #print min(x1, x2), max(x1, x2), abs(x1-x2)\n",
        "        x1 += x_offset\n",
        "        x2 += x_offset\n",
        "        x1 *= x_scaling\n",
        "        x2 *= x_scaling\n",
        "        SV.add_element(svg_arrow(x1, y, x2, y, col, 3))\n",
        "    return SV\n",
        "\n",
        "q_name = overlap_data.keys()[0]\n",
        "OSV = generate_overlap_view(overlap_data, q_name)\n",
        "display(OSV.svg)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('0x9ba164ba_0123315', -32790, 99.8631, (0, 0, 6571, 6571), (0, 38, 6610, 7974))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {}
        }
      ],
      "metadata": {
        "id": "LvLIgGGSvuwU",
        "outputId": "6efb8d40-95a8-41a2-f89d-ada375de7ede"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the \"best overlap graph\"\n",
        "---------------------------------\n",
        "\n",
        "Given that we see a beautiful circle overlapping graph, we like to see if can choose a seeding frgament and extend the overlapping to form a contigs.\n",
        "The code below scans through the ``overlap_data`` and assign the best score alignments for both 3' and 5' of a read as the best partner. The return of the ``get_best_overlap_graph`` is a dictionary where the key is a fragment identifier and the value is the alignment information of the 3' and 5' best overlapping alignments."
      ],
      "metadata": {
        "id": "XqYYHH8RvuwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_overlap_hit(overlap_hit):\n",
        "    containment_tolerance = 50\n",
        "    q_strand, q_start, q_end, q_len = overlap_hit[3]\n",
        "    t_strand, t_start, t_end, t_len = overlap_hit[4]\n",
        "    if q_len - (q_end - q_start) < containment_tolerance and  t_len - (t_end - t_start) / t_len < containment_tolerance:\n",
        "        return False\n",
        "    elif overlap_hit[0] in contained_reads:\n",
        "        return False\n",
        "    else:\n",
        "        return True\n",
        "\n",
        "def get_best_overlap_graph(overlap_data):\n",
        "    best_overlap_graph = {}\n",
        "    containment_tolerance = 50\n",
        "\n",
        "    for q_name in overlap_data:\n",
        "        if q_name in contained_reads:\n",
        "            continue\n",
        "\n",
        "        if q_name not in best_overlap_graph:\n",
        "            best_overlap_graph[q_name] = {\"5p\":None, \"3p\":None}\n",
        "\n",
        "\n",
        "        targets = overlap_data[ q_name ].hits\n",
        "\n",
        "        targets_5prime = [ h for h in targets if h[3][1] < containment_tolerance and filter_overlap_hit(h)]\n",
        "        targets_3prime = [ h for h in targets if h[4][1] < containment_tolerance and filter_overlap_hit(h)]\n",
        "\n",
        "        targets_5prime.sort(key = lambda k:k[1])\n",
        "        targets_3prime.sort(key = lambda k:k[1])\n",
        "\n",
        "        if len(targets_5prime) > 0:\n",
        "            best_overlap_graph[q_name][\"5p\"] = targets_5prime[0]\n",
        "            t_name = targets_5prime[0][0]\n",
        "\n",
        "\n",
        "        if len(targets_3prime) > 0:\n",
        "            best_overlap_graph[q_name][\"3p\"] = targets_3prime[0]\n",
        "            t_name = targets_3prime[0][0]\n",
        "\n",
        "    return best_overlap_graph"
      ],
      "outputs": [],
      "metadata": {
        "id": "LWPv9W-cvuwV"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the output of ``get_best_overlap_graph``\n",
        "----------------------------------------------\n",
        "The cell below find the best alignment from the read of the first key in the ``best_overlap_graph``. It shows the best 3' and 5' partners."
      ],
      "metadata": {
        "id": "iPnRL_NRvuwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_overlap_graph = get_best_overlap_graph(overlap_data)\n",
        "q_name = best_overlap_graph.keys()[0]\n",
        "print q_name, \"has best partners:\", best_overlap_graph[q_name]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0xf6bb6a22_0085668 has best partners: {'3p': ('0xdcf35477_0042197', -37729, 99.9206, (0, 1032, 8586, 8586), (1, 0, 7557, 9323)), '5p': ('0xd9132340_0068296', -40160, 99.373, (0, 0, 8128, 8586), (1, 436, 8525, 8525))}\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "Z69BvlrSvuwV",
        "outputId": "7710c4bc-3f3f-4764-b865-2f529af1d96b"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Find a best overlapping path from a seeding fragment\n",
        "----------------------------------------------------\n",
        "\n",
        "The two functions defined below allows us to extend the overlapping through the chain of overlapped fragments. The extension is terminated when (1) some inconsistent overlapping is detected (2) the overlapped fragment is already used by other contigs (3) no overlapped fragment is found and (4) a circle is detected in the path. Such rules may not be the best way to generate unitigs but they are very simple to implement. At least, these rules do work well for this E. coli data set. One can image some more complicated scenarios that it will be necessary to refine these rules or add more rules to get the best results and avoid mis-assemblies.\n"
      ],
      "metadata": {
        "id": "i3k-Xd8fvuwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def proper_overlap_hit(overlap_hit):\n",
        "    containment_tolerance = 50\n",
        "    q_strand, q_start, q_end, q_len = overlap_hit[3]\n",
        "    t_strand, t_start, t_end, t_len = overlap_hit[4]\n",
        "    if q_start < containment_tolerance:\n",
        "        if t_len - t_end > containment_tolerance:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "    if t_start < containment_tolerance:\n",
        "        if q_len - q_end > containment_tolerance:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "def find_path( q_name_end, frag_used = set() ):\n",
        "    reverse_end = {\"3p\":\"5p\", \"5p\":\"3p\"}\n",
        "    path = []\n",
        "    path_q_name = set()\n",
        "    q_name, end = q_name_end\n",
        "    if end == \"5p\":\n",
        "        reversing_path = True\n",
        "    else:\n",
        "        reversing_path = False\n",
        "\n",
        "    while 1:\n",
        "        if q_name in frag_used:\n",
        "            if reversing_path:\n",
        "                path.reverse()\n",
        "            return path, \"frag_used\"\n",
        "\n",
        "        path.append( (q_name, end) )\n",
        "        path_q_name.add(q_name)\n",
        "        if q_name not in best_overlap_graph:\n",
        "            if reversing_path:\n",
        "                path.reverse()\n",
        "            return path, \"terminate_1\"\n",
        "        next_hit = best_overlap_graph[q_name][end]\n",
        "        #print next_hit\n",
        "        if next_hit == None:\n",
        "            if reversing_path:\n",
        "                path.reverse()\n",
        "            return path, \"terminate_2\"\n",
        "\n",
        "        if next_hit[0] in best_overlap_graph: #if not mutual good hits, break the path\n",
        "\n",
        "            # Using mutual best hit might be to strigent,\n",
        "            # bh = []\n",
        "            #if best_overlap_graph[next_hit[0]][\"5p\"]:\n",
        "            #    bh.append( best_overlap_graph[next_hit[0]][\"5p\"][0] )\n",
        "            #if best_overlap_graph[next_hit[0]][\"3p\"]:\n",
        "            #    bh.append( best_overlap_graph[next_hit[0]][\"3p\"][0] )\n",
        "\n",
        "            bh = [h[0] for h in overlap_data[next_hit[0]].hits if proper_overlap_hit(h)]\n",
        "\n",
        "            if q_name not in bh:\n",
        "                if reversing_path:\n",
        "                    path.reverse()\n",
        "                return path, \"branch\"\n",
        "\n",
        "        q_name = next_hit[0]\n",
        "\n",
        "        if q_name in path_q_name:\n",
        "            if reversing_path:\n",
        "                path.reverse()\n",
        "            return path, \"circle\"\n",
        "\n",
        "        if next_hit[4][0] == 1: #reversed strand\n",
        "            end = reverse_end[end]\n",
        "\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "_SVxsQ0ivuwW"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examples of the best overlapping paths\n",
        "--------------------------------------\n",
        "\n",
        "Here we show how to call the ``find_path`` function to get the overlapping path for both 5' and 3' from a seed fragment. We pick the longest fragment in the data set as the seed.  One will notice that the total fragments in from both 5'-parh and 3'-path are greater than the total number of fragments in the ``best_overlap_graph``. It mean that there are significant overlapping between the 5'-path and 3'-path. This is consistent with the genome is circular."
      ],
      "metadata": {
        "id": "EbETlQhFvuwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len_qname = [ (overlap_data[x].length, x) for x in best_overlap_graph.keys() ]\n",
        "len_qname.sort()\n",
        "q_name = len_qname[-1][1]\n",
        "#q_name = \"0xa4919d66_0061381\"\n",
        "print \"The longest fragment is\", q_name\n",
        "\n",
        "path_5p, s_5p = find_path( (q_name, \"5p\") )\n",
        "path_3p, s_3p = find_path( (q_name, \"3p\") )\n",
        "print \"The number of the fragment of the 5' path is\", len(path_5p)\n",
        "print \"The number of the fragment of the 3' path is\", len(path_3p)\n",
        "print \"The total number of framgent of both 3' and 5' path is %d.\" % (len(path_3p)+len(path_5p)-1)\n",
        "print \"%d is greater than the total number of fragments %d in the best_overlap_graph.\" % (len(path_3p)+len(path_5p)-1, len(best_overlap_graph))\n",
        "print \"The begin of the 5'-path is\", path_5p[0]\n",
        "print \"The end of the 3'-path is\", path_3p[-1]"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The longest fragment is 0x4eaa5fa7_0001083\n",
            "The number of the fragment of the 5' path is"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 2221\n",
            "The number of the fragment of the 3' path is 2158\n",
            "The total number of framgent of both 3' and 5' path is 4378.\n",
            "4378 is greater than the total number of fragments 3390 in the best_overlap_graph.\n",
            "The begin of the 5'-path is ('0xa4919d66_0061381', '3p')\n",
            "The end of the 3'-path is ('0x24a73353_0082329', '3p')\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "cR0XpvgfvuwW",
        "outputId": "02be7dca-d160-4060-a47a-0f0a7e3ad2ba"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a squence database\n",
        "------------------------\n",
        "Since we get the paths that seems covering the whole genome, we can use the paths to construct draft contigs. In order to do that, we need to get the fragment sequences."
      ],
      "metadata": {
        "id": "g6tSlTOsvuwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seq_db = {}\n",
        "with open(\"pre_assembled_reads.fa\") as seq_file:\n",
        "    for l in seq_file:\n",
        "        l = l.strip()\n",
        "        if l[0] == \">\":\n",
        "            name = l[1:]\n",
        "            continue\n",
        "        else:\n",
        "            seq_db[name] = l"
      ],
      "outputs": [],
      "metadata": {
        "id": "LNIVF12SvuwX"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a \"draft\" contig using the best overlapping paths\n",
        "-------------------------------------------------------\n",
        "\n",
        "The ``layout_path`` function goes through a layout path and fill in the base from the fragment sequences. Nothing is really special here. However, it is alwaye tricky to track the right orientation of the fragements. The function also tracks the fragments used in the layout. Each fragement can only be assigned to one layout/contig."
      ],
      "metadata": {
        "id": "ehzhxS_QvuwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rc_seq(seq):\n",
        "    rev_map = dict(zip(\"acgtACGTNn-\",\"tgcaTGCANn-\"))\n",
        "    return \"\".join([rev_map[c] for c in seq[::-1]])\n",
        "\n",
        "def layout_path(full_path, frag_used, out_fn, tig_name):\n",
        "\n",
        "    if len(full_path) == 0 or full_path[0][0] in frag_used:\n",
        "        return None\n",
        "\n",
        "    if len(full_path) == 1:\n",
        "        with open(\"singleton_\"+out_fn, \"w\") as out_seq_file:\n",
        "            seq = seq_db[full_path[0][0]]\n",
        "            print >>out_seq_file, \">%s\" % ( \"singleton_\" + tig_name  )\n",
        "            print >>out_seq_file, seq\n",
        "            frag_used.add(full_path[0][0])\n",
        "        return None\n",
        "\n",
        "    first = full_path[0]\n",
        "    offset = 0\n",
        "    current_orientation = first[1]\n",
        "    revserse_orientation = {\"5p\":\"3p\", \"3p\":\"5p\"}\n",
        "    tig_seq = []\n",
        "    frag_in_layout = set()\n",
        "    frag_in_layout.add(first[0])\n",
        "    for second in full_path[1:]:\n",
        "        overlap_hit = overlap_data[first[0]][second[0]]\n",
        "\n",
        "        q_strand, q_start, q_end, q_len = overlap_hit[3]\n",
        "        t_strand, t_start, t_end, t_len = overlap_hit[4]\n",
        "        #print overlap_hit, offset, current_orientation\n",
        "        seq = seq_db[first[0]]\n",
        "        if current_orientation == \"3p\":\n",
        "            seq = rc_seq(seq)\n",
        "        del tig_seq[offset:-1]\n",
        "        tig_seq.extend(seq)\n",
        "\n",
        "        if current_orientation == \"5p\":\n",
        "            offset += q_start\n",
        "        elif current_orientation == \"3p\":\n",
        "            offset += q_len - q_end\n",
        "        if t_strand == 1:\n",
        "           current_orientation  = revserse_orientation[current_orientation]\n",
        "        frag_in_layout.add(first[0])\n",
        "        first = second\n",
        "        if second[0] in frag_in_layout:\n",
        "            break\n",
        "        if second[0] in frag_used:\n",
        "            break\n",
        "\n",
        "    seq = seq_db[first[0]]\n",
        "    if current_orientation == \"3p\":\n",
        "        seq = rc_seq(seq)\n",
        "    del tig_seq[offset:-1]\n",
        "    tig_seq.extend(seq)\n",
        "    frag_in_layout.add(first[0])\n",
        "\n",
        "    frag_used.update( frag_in_layout )\n",
        "\n",
        "    tig_seq = tig_seq[0:offset+len(seq)]\n",
        "    tig_seq = \"\".join(tig_seq)\n",
        "    with open(out_fn, \"w\") as out_seq_file:\n",
        "        print >>out_seq_file, \">%s\" % tig_name\n",
        "        print >>out_seq_file, tig_seq"
      ],
      "outputs": [],
      "metadata": {
        "id": "UDh2FOBDvuwX"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loop through all fragments to generate all contigs and singletons\n",
        "-----------------------------------------------------------------\n",
        "\n",
        "Ok, ready for the primer time!!\n",
        "\n",
        "The code below will pick the longest fragment as the first seed and generate a contig from its overlapping path. Then, we will pick another longest one from those reads that have not been used in a contig. This process repeats until no more fragement is avaiable.\n",
        "\n",
        "In the data set, we generate one big contig (4650011 bp) and 49 singleton reads."
      ],
      "metadata": {
        "id": "nvYhuKmevuwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frag_used = set()\n",
        "\n",
        "all_best_overlap_frags = set(best_overlap_graph.keys())\n",
        "\n",
        "unused_frag = all_best_overlap_frags - frag_used\n",
        "i = 0\n",
        "while len(unused_frag) != 0:\n",
        "\n",
        "    len_qname = [ (overlap_data[x].length, x) for x in unused_frag  ]\n",
        "    len_qname.sort()\n",
        "    q_name = len_qname[-1][1]\n",
        "    print \"iteration: \",i\n",
        "    print \"frag is used?\", q_name in frag_used\n",
        "    if q_name in frag_used:\n",
        "        continue\n",
        "\n",
        "    path_5p, s_5p = find_path( (q_name, \"5p\"), frag_used  )\n",
        "    path_3p, s_3p = find_path( (q_name, \"3p\"), frag_used  )\n",
        "    print \"seeding frag:\", q_name, \"Length:\", overlap_data[q_name].length\n",
        "    print \"number of unused frag:\", len(unused_frag), \"total overlapped frag:\", len(path_3p)+len(path_5p)\n",
        "    print len(path_5p), s_5p, len(path_3p), s_3p\n",
        "    print \"--------------------------\"\n",
        "    #print path_5p[0], path_3p[-1]\n",
        "    if len(path_5p) + len(path_3p) == 0:\n",
        "        out_fn = \"tig_%05d.fa\" % i\n",
        "        tig_name =\"tig%05d\" % i\n",
        "        with open(\"singleton_\"+out_fn, \"w\") as out_seq_file:\n",
        "            seq = seq_db[q_name]\n",
        "            print >>out_seq_file, \">%s\" % ( \"singleton_\" + tig_name  )\n",
        "            print >>out_seq_file, seq\n",
        "        frag_used.add(q_name)\n",
        "        unused_frag = all_best_overlap_frags - frag_used\n",
        "        i += 1\n",
        "        continue\n",
        "\n",
        "    if len(path_5p) > 0:\n",
        "        #assert path_5p[-1] == path_3p[0]\n",
        "\n",
        "        full_path = path_5p + path_3p[1:]\n",
        "    else:\n",
        "        full_path = path_3p\n",
        "    layout_path(full_path, frag_used, \"tig_%05d.fa\" % i, \"tig%05d\" % i)\n",
        "    unused_frag = all_best_overlap_frags - frag_used\n",
        "    i += 1\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration:  0\n",
            "frag is used? False\n",
            "seeding frag:"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 0x4eaa5fa7_0001083 Length: 14762\n",
            "number of unused frag: 3390 total overlapped frag: 4379\n",
            "2221 terminate_2 2158 terminate_2\n",
            "--------------------------\n",
            "iteration: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 1\n",
            "frag is used? False\n",
            "seeding frag: 0x720a6867_0101011 Length: 9562\n",
            "number of unused frag: 64 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  2\n",
            "frag is used? False\n",
            "seeding frag: 0xbb3ff171_0040732 Length: 8653\n",
            "number of unused frag: 63 total overlapped frag: 2\n",
            "1 branch 1 branch\n",
            "--------------------------\n",
            "iteration:  3\n",
            "frag is used? False\n",
            "seeding frag: 0xf9f76d57_0075336 Length: 8601\n",
            "number of unused frag: 62 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  4\n",
            "frag is used? False\n",
            "seeding frag: 0x24a73353_0082329 Length: 8529\n",
            "number of unused frag: 61 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  5\n",
            "frag is used? False\n",
            "seeding frag: 0x99a801d6_0119226 Length: 8390\n",
            "number of unused frag: 60 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  6\n",
            "frag is used? False\n",
            "seeding frag: 0x3176999f_0092788 Length: 8012\n",
            "number of unused frag: 59 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  7\n",
            "frag is used? False\n",
            "seeding frag: 0xd1f5cb9c_0041132 Length: 7742\n",
            "number of unused frag: 58 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  8\n",
            "frag is used? False\n",
            "seeding frag: 0x6a67d4d1_0054113 Length: 7635\n",
            "number of unused frag: 57 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  9\n",
            "frag is used? False\n",
            "seeding frag: 0x5e62b551_0087810 Length: 7612\n",
            "number of unused frag: 56 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  10\n",
            "frag is used? False\n",
            "seeding frag: 0x47c817fa_0037671 Length: 7592\n",
            "number of unused frag: 55 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  11\n",
            "frag is used? False\n",
            "seeding frag: 0xd34bbcb8_0096026 Length: 7586\n",
            "number of unused frag: 54 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  12\n",
            "frag is used? False\n",
            "seeding frag: 0xde53c97d_0130793 Length: 7568\n",
            "number of unused frag: 53 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  13\n",
            "frag is used? False\n",
            "seeding frag: 0xbab42971_0019685 Length: 7462\n",
            "number of unused frag: 52 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  14\n",
            "frag is used? False\n",
            "seeding frag: 0x95dcccbf_0021944 Length: 7446\n",
            "number of unused frag: 51 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  15\n",
            "frag is used? False\n",
            "seeding frag: 0x7b49a930_0025802 Length: 7402\n",
            "number of unused frag: 50 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  16\n",
            "frag is used? False\n",
            "seeding frag: 0xec2de5ef_0014019 Length: 7335\n",
            "number of unused frag: 49 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  17\n",
            "frag is used? False\n",
            "seeding frag: 0xb48bdbdf_0062004 Length: 7033\n",
            "number of unused frag: 48 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  18\n",
            "frag is used? False\n",
            "seeding frag: 0x201a3501_0131298 Length: 6986\n",
            "number of unused frag: 47 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  19\n",
            "frag is used? False\n",
            "seeding frag: 0xa3d2663c_0086930 Length: 6961\n",
            "number of unused frag: 46 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  20\n",
            "frag is used? False\n",
            "seeding frag: 0xe092bfc0_0025000 Length: 6941\n",
            "number of unused frag: 45 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  21\n",
            "frag is used? False\n",
            "seeding frag: 0x101cf700_0133174 Length: 6913\n",
            "number of unused frag: 44 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  22\n",
            "frag is used? False\n",
            "seeding frag: 0x27b1b79d_0098081 Length: 6687\n",
            "number of unused frag: 43 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  23\n",
            "frag is used? False\n",
            "seeding frag: 0x746a0885_0091093 Length: 6663\n",
            "number of unused frag: 42 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  24\n",
            "frag is used? False\n",
            "seeding frag: 0xf16e1447_0062854 Length: 6502\n",
            "number of unused frag: 41 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  25\n",
            "frag is used? False\n",
            "seeding frag: 0x2e1dde37_0073961 Length: 6444\n",
            "number of unused frag: 40 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  26\n",
            "frag is used? False\n",
            "seeding frag: 0x39af8897_0112579 Length: 6439\n",
            "number of unused frag: 39 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  27\n",
            "frag is used? False\n",
            "seeding frag: 0x4252156_0076315 Length: 6326\n",
            "number of unused frag: 38 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  28\n",
            "frag is used? False\n",
            "seeding frag: 0x8b32b9de_0082459 Length: 6255\n",
            "number of unused frag: 37 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  29\n",
            "frag is used? False\n",
            "seeding frag: 0xc0298763_0082661 Length: 6235\n",
            "number of unused frag: 36 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  30\n",
            "frag is used? False\n",
            "seeding frag: 0xfe2ddc8f_0006613 Length: 6219\n",
            "number of unused frag: 35 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  31\n",
            "frag is used? False\n",
            "seeding frag: 0xf2c9d7d9_0019647 Length: 6209\n",
            "number of unused frag: 34 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  32\n",
            "frag is used? False\n",
            "seeding frag: 0x5f497891_0044312 Length: 6178\n",
            "number of unused frag: 33 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  33\n",
            "frag is used? False\n",
            "seeding frag: 0x9d1fd3d5_0003951 Length: 6142\n",
            "number of unused frag: 32 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  34\n",
            "frag is used? False\n",
            "seeding frag: 0xd3405c1f_0120478 Length: 6056\n",
            "number of unused frag: 31 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  35\n",
            "frag is used? False\n",
            "seeding frag: 0xd84402bc_0135092 Length: 6022\n",
            "number of unused frag: 30 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  36\n",
            "frag is used? False\n",
            "seeding frag: 0x8e9f3eb7_0077492 Length: 6020\n",
            "number of unused frag: 29 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  37\n",
            "frag is used? False\n",
            "seeding frag: 0x6560473d_0129910 Length: 6009\n",
            "number of unused frag: 28 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  38\n",
            "frag is used? False\n",
            "seeding frag: 0x8e21ba01_0028034 Length: 5945\n",
            "number of unused frag: 27 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  39\n",
            "frag is used? False\n",
            "seeding frag: 0x328d5dfc_0076264 Length: 5867\n",
            "number of unused frag: 26 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  40\n",
            "frag is used? False\n",
            "seeding frag: 0x8c4c9750_0115911 Length: 5854\n",
            "number of unused frag: 25 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  41\n",
            "frag is used? False\n",
            "seeding frag: 0x99d966a0_0043182 Length: 5848\n",
            "number of unused frag: 24 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration: "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 42\n",
            "frag is used? False\n",
            "seeding frag: 0xebaae05c_0001651 Length: 5718\n",
            "number of unused frag: 23 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  43\n",
            "frag is used? False\n",
            "seeding frag: 0x6015c8f3_0137444 Length: 5607\n",
            "number of unused frag: 22 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  44\n",
            "frag is used? False\n",
            "seeding frag: 0x820c3016_0097966 Length: 5594\n",
            "number of unused frag: 21 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  45\n",
            "frag is used? False\n",
            "seeding frag: 0xfb73db8e_0019839 Length: 5523\n",
            "number of unused frag: 20 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  46\n",
            "frag is used? False\n",
            "seeding frag: 0x5842b8b1_0141185 Length: 5483\n",
            "number of unused frag: 19 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  47\n",
            "frag is used? False\n",
            "seeding frag: 0x2876a699_0009758 Length: 5403\n",
            "number of unused frag: 18 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  48\n",
            "frag is used? False\n",
            "seeding frag: 0xf936c2fd_0094203 Length: 5372\n",
            "number of unused frag: 17 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  49\n",
            "frag is used? False\n",
            "seeding frag: 0xe5322dba_0130928 Length: 5027\n",
            "number of unused frag: 16 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  50\n",
            "frag is used? False\n",
            "seeding frag: 0x2ac1140b_0130957 Length: 4894\n",
            "number of unused frag: 15 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  51\n",
            "frag is used? False\n",
            "seeding frag: 0x53d92d4b_0116355 Length: 4758\n",
            "number of unused frag: 14 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  52\n",
            "frag is used? False\n",
            "seeding frag: 0xe09961a7_0000768 Length: 4746\n",
            "number of unused frag: 13 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  53\n",
            "frag is used? False\n",
            "seeding frag: 0x6bdaa7bf_0024191 Length: 4530\n",
            "number of unused frag: 12 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  54\n",
            "frag is used? False\n",
            "seeding frag: 0x2d6f1fdb_0064584 Length: 4419\n",
            "number of unused frag: 11 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  55\n",
            "frag is used? False\n",
            "seeding frag: 0xe6c70a1b_0009216 Length: 4386\n",
            "number of unused frag: 10 total overlapped frag: 2\n",
            "1 frag_used 1 frag_used\n",
            "--------------------------\n",
            "iteration:  56\n",
            "frag is used? False\n",
            "seeding frag: 0x1bed69cc_0052813 Length: 4332\n",
            "number of unused frag: 9 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  57\n",
            "frag is used? False\n",
            "seeding frag: 0xc48ec0c3_0089324 Length: 4173\n",
            "number of unused frag: 8 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  58\n",
            "frag is used? False\n",
            "seeding frag: 0x2afb8806_0097596 Length: 3840\n",
            "number of unused frag: 7 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  59\n",
            "frag is used? False\n",
            "seeding frag: 0xf953ded0_0012908 Length: 2975\n",
            "number of unused frag: 6 total overlapped frag: 2\n",
            "1 frag_used 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  60\n",
            "frag is used? False\n",
            "seeding frag: 0x3b256f1f_0102519 Length: 2397\n",
            "number of unused frag: 5 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  61\n",
            "frag is used? False\n",
            "seeding frag: 0x3f31dab0_0019006 Length: 2040\n",
            "number of unused frag: 4 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  62\n",
            "frag is used? False\n",
            "seeding frag: 0xcc88cea2_0015902 Length: 1651\n",
            "number of unused frag: 3 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n",
            "iteration:  63\n",
            "frag is used? False\n",
            "seeding frag: 0x2708c7d8_0113402 Length: 1617\n",
            "number of unused frag: 2 total overlapped frag: 2\n",
            "1 terminate_2 1 terminate_2\n",
            "--------------------------\n",
            "iteration:  64\n",
            "frag is used? False\n",
            "seeding frag: 0x612f720b_0078835 Length: 1275\n",
            "number of unused frag: 1 total overlapped frag: 2\n",
            "1 terminate_2 1 frag_used\n",
            "--------------------------\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "xO62eAypvuwX",
        "outputId": "850186f1-7707-4c43-8fda-f80deb18d5d7"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the singletons?\n",
        "================================\n",
        "\n",
        "One can align the contigs to the canoincal E. coli K12 reference to evaluate the quality of the assembly. One can see from the alignment data below, it seems that some fragments have lower accuracy that does not pass the 98% identity threshold to be called \"overlapped\" with other fragments. Three of them does not have full alginments. In this case, one will need to examine the raw reads that corresponds to these three fragments to see whether they are minor variants or some lower quality reads are not filtered."
      ],
      "metadata": {
        "id": "8ElDYZK_vuwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cat singleton_tig_000* > singletons.fa\n",
        "!blasr singletons.fa ecoli_k12_MG1655.fasta -m 4 -noSplitSubreads -nCandidates 20 -bestn 1 | awk '{print $1\" \"$2\" \"$4\" \"$6\" \"$7\" \"$8\" \"$8-($7-$6)}'"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00001 Escherichia_coli_K12 97.4017 0 9562 9562 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00002 Escherichia_coli_K12 97.3956 1431 8653 8653 1431\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00003 Escherichia_coli_K12 98.432 0 8601 8601 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00004 Escherichia_coli_K12 98.3834 0 8529 8529 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00005 Escherichia_coli_K12 99.4192 0 8390 8390 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00006 Escherichia_coli_K12 97.3447 0 8012 8012 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00007 Escherichia_coli_K12 98.1237 0 7742 7742 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00008 Escherichia_coli_K12 97.7821 0 7635 7635 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00009 Escherichia_coli_K12 98.2443 0 7612 7612 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00010 Escherichia_coli_K12 99.1766 2 7592 7592 2\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00011 Escherichia_coli_K12 97.1927 0 7586 7586 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00012 Escherichia_coli_K12 96.5121 0 7558 7568 10\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00013 Escherichia_coli_K12 97.4269 0 7462 7462 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00014 Escherichia_coli_K12 98.3228 0 7446 7446 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00015 Escherichia_coli_K12 99.4492 0 7402 7402 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00016 Escherichia_coli_K12 98.9734 0 7335 7335 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00017 Escherichia_coli_K12 97.9114 0 7033 7033 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00018 Escherichia_coli_K12 97.6773 0 6986 6986 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00019 Escherichia_coli_K12 96.437 0 6961 6961 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00020 Escherichia_coli_K12 97.4028 0 6941 6941 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00021 Escherichia_coli_K12 97.5844 0 6913 6913 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00022 Escherichia_coli_K12 99.1106 0 6687 6687 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00023 Escherichia_coli_K12 98.9452 0 6663 6663 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00024 Escherichia_coli_K12 97.4351 0 6502 6502 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00025 Escherichia_coli_K12 97.3736 0 6444 6444 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00026 Escherichia_coli_K12 96.5362 0 6439 6439 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00027 Escherichia_coli_K12 97.9105 0 6326 6326 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00028 Escherichia_coli_K12 97.7177 0 6255 6255 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00029 Escherichia_coli_K12 98.0028 0 6235 6235 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00030 Escherichia_coli_K12 98.09 0 6219 6219 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00031 Escherichia_coli_K12 95.9777 0 6209 6209 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00032 Escherichia_coli_K12 97.8922 0 6178 6178 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00033 Escherichia_coli_K12 97.8164 0 6142 6142 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00034 Escherichia_coli_K12 99.2136 0 6056 6056 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00035 Escherichia_coli_K12 97.2532 0 6022 6022 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00036 Escherichia_coli_K12 97.854 0 6020 6020 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00037 Escherichia_coli_K12 97.1526 0 6009 6009 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00038 Escherichia_coli_K12 96.5394 0 5945 5945 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00039 Escherichia_coli_K12 97.2628 0 5867 5867 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00040 Escherichia_coli_K12 97.3697 0 5854 5854 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00041 Escherichia_coli_K12 97.9883 0 5848 5848 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00042 Escherichia_coli_K12 97.7751 0 5718 5718 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00043 Escherichia_coli_K12 97.9378 0 5607 5607 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00044 Escherichia_coli_K12 99.2899 0 5594 5594 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00045 Escherichia_coli_K12 98.4484 0 5523 5523 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00046 Escherichia_coli_K12 97.7524 0 5483 5483 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00047 Escherichia_coli_K12 83.9108 0 5403 5403 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00048 Escherichia_coli_K12 97.5472 0 5372 5372 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00049 Escherichia_coli_K12 97.8931 0 5027 5027 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00050 Escherichia_coli_K12 97.9968 0 4894 4894 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00051 Escherichia_coli_K12 97.739 0 4758 4758 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00052 Escherichia_coli_K12 94.8541 58 4746 4746 58\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00053 Escherichia_coli_K12 97.3543 0 4530 4530 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00054 Escherichia_coli_K12 95.1304 0 4419 4419 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00055 Escherichia_coli_K12 96.9268 0 4386 4386 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00056 Escherichia_coli_K12 97.6502 0 4332 4332 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00057 Escherichia_coli_K12 97.4755 0 4173 4173 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00058 Escherichia_coli_K12 97.8816 0 3840 3840 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00059 Escherichia_coli_K12 97.7303 0 2975 2975 0\r\n",
            "singleton_tig00060 Escherichia_coli_K12 96.2158 0 2397 2397 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00061 Escherichia_coli_K12 97.5586 0 2040 2040 0\r\n",
            "singleton_tig00062 Escherichia_coli_K12 97.5768 0 1651 1651 0\r\n",
            "singleton_tig00063 Escherichia_coli_K12 97.8221 0 1617 1617 0\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "singleton_tig00064 Escherichia_coli_K12 97.032 0 1275 1275 0\r\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "7VSl8RqwvuwY",
        "outputId": "442d2f86-7e53-4ead-c40a-014132435dd4"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "How good is the main contig?\n",
        "============================\n",
        "\n",
        "The main contig is 4650011bp. It seems that it should cover the whole genome.  We can see the whole genome alignment using\n",
        "[``gepard``]( http://www.helmholtz-muenchen.de/en/mips/services/analysis-tools/gepard/index.html ). We can see there is no larger scale mis-assembly. Promising!! (The strand of the K12 for this data is actuall slight different from the canonical one. We do expect to see some small structure variations.)"
      ],
      "metadata": {
        "id": "nm7wc-kPvuwY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=\"tig_align.jpeg\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {},
          "execution_count": 19
        }
      ],
      "metadata": {
        "id": "lLTTXutevuwY",
        "outputId": "ab5ad1a7-4b42-4c6a-f461-c37a6f35101d"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy?\n",
        "---------\n",
        "We don't expect to get high accuracy from the \"draft\" assembly. The way we construct the contig is just to copy-and-paste from the pre-assembled reads which have mean identity 99.789% to the reference genome. For a 4.7Mb genome, we will expect 4700000 * (1-0.99787) ~ 10k differences. One can do another round of consensus using the pre-assembled reads. Or, we can align the raw reads on top of the draft contig and apply the \"Quiver\" algorithm to get the best accuracy from all raw data. Let's see how \"Quiver\" helps to remove the errors in the draft contig."
      ],
      "metadata": {
        "id": "pB3MTRFyvuwe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's evalute the differece between the draft contigs to the canonical reference with the ``dnadiff`` from\n",
        "[Mummer3 package](http://mummer.sourceforge.net/)"
      ],
      "metadata": {
        "id": "k53xKowPvuwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!dnadiff ecoli_k12_MG1655.fasta tig_00000.fa -p diff_tig0\n",
        "!echo the number of SNPs is `cat diff_tig0.snps  | wc | awk '{print $1}'`"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of SNPs is 10026\r\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "y9OR2WvQvuwe",
        "outputId": "dd0f144f-032a-4e5b-95f5-ddf7ad6fd739"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The draft contig has about 10k SNPs as what we expect from the estimation earlier. We apply ``Quvier`` consensus algorithm on the the draft contig using the following script::\n",
        "\n",
        "    #!/bin/bash\n",
        "    export SEYMOUR_HOME=/PathTo/PacBio/SMRTAnalysis\n",
        "    . $SEYMOUR_HOME/etc/setup.sh\n",
        "    cd /Path/To/WorkingDirectory\n",
        "    cp tig_00000.fa asm.ctg.fasta\n",
        "    referenceUploader -c -p $PWD -n assembly -f asm.ctg.fasta --skipIndexUpdate\n",
        "\n",
        "    compareSequences.py --info --useGuidedAlign --algorithm=blasr --nproc=24 --noXML --h5mode=w --h5fn=out.cmp.h5 --minAccuracy=0.70 --minLength=200 \\\n",
        "    -x -nCandidates 50 -x -minMatch 12 -x -bestn 1 -x -minPctIdentity 70.0 /Path/To/WorkingDirectory/input.fofn assembly/\n",
        "    \n",
        "    loadPulses /Path/To/WorkingDirectory/input.fofn out.cmp.h5\\\n",
        "    -metrics DeletionQV,IPD,InsertionQV,PulseWidth,QualityValue,MergeQV,SubstitutionQV,DeletionTag -byread \\\n",
        "    \n",
        "    cmph5tools.py sort out.cmp.h5 --tmp /scratch\n",
        "    \n",
        "    variantCaller.py --algorithm quiver -j 16 --referenceFilename assembly/sequence/assembly.fasta \\\n",
        "    --parameters best -o output.gff  -o output.fasta -o output.fastq -q 0  -X 80 -x 5 --mapQvThreshold 0 out.cmp.h5\n",
        "\n",
        "This will generate the consensus sequence using Quiver. The consensus output is in ``output.fasta``. We find 26 SNPs in the final consensus results. This gives a lower bound of the final assembly phred QV about -10*log10(26/4639675) = 52.5.  One can see that the ``Quiver`` algorithm which utilizes all important information from the raw trace signal is able to correct the ~10k errors in the\n",
        "draft assembly. This allows us more freedom while constructing the initial draft assembly.  We do not need to construct perfect draft assembly from perfect reads. The goal for constructing the draft is to get the contiguity right. Given the long reads, one can expect that most mapping is unambiguous and that will lead to almost perfect consensus using ``Quiver``.\n"
      ],
      "metadata": {
        "id": "G2vLKs2Ovuwe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dnadiff ecoli_k12_MG1655.fasta output.fasta -p diff_quiver_tig0\n",
        "!echo the number of SNPs is `cat diff_quiver_tig0.snps | wc | awk '{print $1}'`\n",
        "from math import log\n",
        "print \"The phred scale QV of the assembly is about %0.1f\" % (-10*log(26.0/4639675)/log(10))\n",
        "print \"The concordnace is about %0.5f%%\" % (100*(1-26.0/4639675))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the number of SNPs is 26\r\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The phred scale QV of the assembly is about 52.5\n",
            "The concordnace is about 99.99944%\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "gVyBu5RRvuwf",
        "outputId": "9a72bf96-a8a1-48c4-bf1e-c1fa8e949987"
      },
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Final Thought\n",
        "=============\n",
        "\n",
        "I had some fun with this exercise. I think this approach is general but it will\n",
        "need more tests for sure. We only have n=1 successful story for now. However,\n",
        "the reality is when we can generate longer and longer reads, the assembly\n",
        "problem will become easier and easier. DNA sequencing is about connecting\n",
        "different bases across distance. Some problems can be only solved by enough\n",
        "read length spans. I do like to see more fundamental theories published about\n",
        "genome assembly and haplotyping (e.g. the classical Lander-Waterman paper and\n",
        "the recent careful analysis done ([preprint](http://arxiv.org/abs/1301.0068))\n",
        "by Davie Tse's group).  Getting good consensus from long reads is\n",
        "probably a relative simpler problem than dealing with combinatorial explosion\n",
        "when one tries to infer long range information using short reads.  Taking\n",
        "bacteria assembly as an example, it is likely impossible to assemble the E.\n",
        "coli K12 genome to single contig with single-end short read library.  Without\n",
        "any long pair-end or jumping libraries, the single-end short read data simply\n",
        "does not the power to resolve various scales of repeat structure in the genome.\n",
        "Such constraints can not be solved by simply sequencing more (see Tse's argument).\n",
        "Actually, regardless how cheap DNA sequencing is, without proper understanding\n",
        "the fundamental theories and mathematical constraints, one could just waste\n",
        "money collecting tons of useless data.  Cheap data still costs money. Cheap data\n",
        "that can not solve problems is actually expansive. One can sequence E coli. K12 genome\n",
        "to 10000x coverage with short read technologies cheaply. However, without\n",
        "proper libraries to get long range information, 10000x coverage from short fragments\n",
        "will still lead to fragmented assemblies. One the other hand, one can see from\n",
        "the example in this ``IPython`` Notebook. Once we can generate good quality long reads,\n",
        "even an assembly newbie like me can put together a prototype of an assembler with python\n",
        "in a few days. By the way, it only takes 20 seconds on my 2012 MacBook Air (Intel i7) to\n",
        "get the draft assembly from the ``m4`` file.\n"
      ],
      "metadata": {
        "id": "NR3bbzoTvuwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!time python Write_An_Assembler.py > /dev/null"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "real\t0m21.142s\r\n",
            "user\t0m20.326s\r\n",
            "sys\t0m0.745s\r\n"
          ],
          "name": "stdout"
        }
      ],
      "metadata": {
        "id": "WPzmH-n_vuwf",
        "outputId": "ddb0772b-c220-4922-dd24-75a8ad314eb0"
      },
      "execution_count": null
    }
  ]
}